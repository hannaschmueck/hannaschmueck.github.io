<!DOCTYPE HTML>
<!--
    Strata by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
    -->
<html>

<head>
    <title>Hanna Schmück</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
</head>


<body class="is-preload">
    <!-- Header -->
    <header id="header">
        <div class="inner"> <a href="https://hannaschmueck.github.io/" class="image avatar"><img src="images/avatar.jpg"
                    alt="" /></a>
            <h1><strong>Research Associate | The University of Augsburg </strong><br />
                <br /> </h1>
        </div>
    </header> <!-- Main -->
    <div id="main">
        <!-- Introduction -->
        <section id="one">
            <header class="major">
              
                <h2>Hanna Schmück </h2>
            </header>

          
            <p> I'm a Research Associate at the University of Augsburg.
                Until recently, I was a a Research Associate at the University of Glasgow where I was working on the linguistic and data visualisation outputs of the <a href="https://OHOS.ac.uk/">OHOS</a> Project. I was also a Research Assistant and Associate Lecturer at Lancaster University where I did my PhD. I greatly enjoy
                all things corpus linguistics, computational linguistics, and data visualisation. The main aim of my work is to
                develop new, explainable methodologies and workflows so we can analyse (existing) linguistic data in new
                ways and further our understanding of language and the mind. I also greatly enjoy working with data from the heritage sector and exploring the concept of language as heritage.
                Have a look at my research/projects, <a
                    href="https://hannaschmueck.github.io/publications" target="_blank">publications</a>, learn more
                about what I get up to, and feel free to get in touch if you want to explore possible collaborations.
        </section>
        <hr class="rounded">


         <h2>Current Role at the University of Augsburg </h2>
        <div class="rounded-box"><b>Research Associate - Chair for Natural Language Understanding (Prof. Friedrich), Faculty of Applied CS</b></div> 
         <p><span class="image right"><img src="images/fulls/UniA.png" alt="" /></span>
            I am a member of the <a href="https://hlt-augsburg.github.io"> HLT@Augsburg</a> group and work on a variety of projects, chiefly (from September 2025) on the <i>Computational Discourse Analysis and Processing across Languages and Time </i> project with <a href="https://annefried.github.io"> Prof. Annemarie Friedrich</a> and <a href="https://jakpra.github.io"> Dr. Jakob Prange</a>.
            As a Research Assistant on this DFG-funded project, I support research developing a computer-aided framework for analysing discourse modes in texts. I co-create annotation guidelines and diachronic corpora, contribute to corpus studies on grammatical structures in historical German texts and discourse patterns in English historiography, and assist with developing computational tools for analysis. Our work extends beyond traditional register-based approaches to examine how passage-level discourse features evolve over time.
  
               <br />I am also teaching the INF-0467: Seminar Natural Language Understanding module (UG + PG).
        
        <h2>Experience at the University of Glasgow </h2>
        <div class="rounded-box"><b>Research Associate - Information Studies, School of Humanities</b></div> 
          <p><span class="image left"><img src="images/fulls/OHOS.jpg" alt="" /></span>
            The project I was working on, <i>Our Heritage, Our Stories</i>, is a Discovery Research Project funded by the Arts and Humanities Research Council, as part of the Towards a National Collection programme. It aims to make community-generated digital content from a large number of different community archives more linkable, searchable, and to make it available alongside custodial resources like The National Archive. My main research area within this project is identifying how corpus linguists can benefit from the rich resources found in community archives and how language can be valued and appreciated as a heritage object. I have also created the visualisation outputs (named entity networks) for the project. These can be found <a href="https://ohos.ac.uk/datasets-and-software/">here</a>. </p>
        <h2>Projects and Experience at Lancaster University </h2>
        <p>
        <ul class="alt">
            <li>
              <div class="rounded-box"><b>Teaching - Undergraduate Modules</b></div>
              <span class="image right"><img src="images/fulls/teaching.jpg" alt="" /></span>
              I have been teaching several modules at <a
                    href="https://www.lancaster.ac.uk/linguistics/about/people/hanna-schmueck" target="_blank">Lancaster
                    University</a> since 2020. Modules I have taught so far include LING228 (Child Language
                Acquisition), LING315 (Forensic Linguistics), LING326 (Corpus Linguistics), LING330 (Language, Cognition and Culture), LING324 (Cognitive Linguistics), and LING316 (Psycholinguistics). </li>
            <li><div class="rounded-box">
              <b>Teaching - MOOC</b>
          </div> 
          <span class="image right"><img src="images/fulls/MOOC.jpg"alt="" /></span>
          I have been deputy lead / lead mentor for Lancaster's <a href="https://www.futurelearn.com/courses/corpus-linguistics" target="_blank">"Corpus Linguistics - Method, Analysis, Interpretation"</a> online course for multiple years now. This course runs yearly, has multiple thousands of participants (at the time of writing a cumulative count of over 70,000) and I have been involved since 2020. 
          </li> 
          <div class="rounded-box"><b>Teaching - Autumn School in Corpus Linguistics</b></div> I was teaching a 13 week autumn school for academics hoping to further their corpus linguistic skills and professional development at Lancaster University.
            <li><div class="rounded-box"><b>Mentoring - Methods North West</b></div> I was working as a mentor for research students as
                part of a <a href="https://twitter.com/MethodsNW/status/1569264899808972800" target="_blank">Methods NW
                    project</a> enabling interdisciplinary and interinstitutional research collaborations. My role
                involved advising the researcher in methodological matters with regards to corpus linguistics.
            <li><div class="rounded-box"><b>Mentoring - Coding Sessions</b></div> I was working as a mentor teaching other
                academics programming skills (R/Python). In this role, I designed a curriculum around the researchers'
                individual project aims, set challenges, and cooperate with them to find efficient, robust,
                interpretable, and easily replicable solutions.
            <li> <div class="rounded-box"><b>Teaching and Technical Assistance - Summer Schools in Corpus Linguistics</b></div>
              I have been helping with the <a href="http://wp.lancs.ac.uk/corpussummerschools/" target="_blank">Lancaster
                    Summer Schools in Corpus Linguistics</a> since 2020. This has involved both teaching Q&A sessions
                as well as helping with the technology behind the scenes (setting up and recording Teams live events,
                monitoring the chat, operating the presentations etc.). </li> 
                
            <li><div class="rounded-box"><b>Research Assistant Roles - BNC Assistant</b></div>

              <span class="image right"><img src="images/fulls/BNC.jpg" alt="" /></span>
              I worked on preprocessing and data cleaning
                of the <a href="https://www.degruyter.com/document/doi/10.1515/text-2020-0052/html?lang=en" target="_blank">British National Corpus 2014</a> from 2020 to its publication in late 2021. <br/><br/><br/><br/></li>
            <li><div class="rounded-box"><b>Research Assistant Roles - Data Processing</b></div>I worked on a syntactic coding project
                doing data cleaning and advanced preprocessing in 2022. </li>
            <li><div class="rounded-box"><b>Research Assistant Roles - Manual Coding</b></div>I started working on a project
                investigating language testing data in the <a
                    href="http://www.research.lancs.ac.uk/portal/en/upmprojects/construction-and-corpusbased-analysis-of-the-british-councillancaster-university-aptis-corpus(3ace9bdf-2dd1-4f72-b9d0-530670fcc2f7).html"
                    target="_blank">APTIS corpus</a>, a corpus compiled in collaboration with the <a
                    href="https://www.britishcouncil.org/" target="_blank">British Council</a>. For this project, I
                carried out manual pragmatic coding. </li>
            <li><div class="rounded-box"><b>Research Assistant Roles - Data Processing</b></div>I worked on L2 language proficiency test
                data, also from the <a
                    href="http://www.research.lancs.ac.uk/portal/en/upmprojects/construction-and-corpusbased-analysis-of-the-british-councillancaster-university-aptis-corpus(3ace9bdf-2dd1-4f72-b9d0-530670fcc2f7).html"
                    target="_blank">APTIS corpus</a>, mainly data processing, formatting and statistical analyses of
                epistemic markers. </li>
            <li><div class="rounded-box"><b>Research Assistant Roles - LANA Corpus Processing</b></div>I worked on the the
                Lancaster-Northern Arizona Corpus of American English <a href="https://twitter.com/LANA_corpus"
                    target="_blank">(LANA) </a> project in collaboration with colleagues at ASU. </li>
            <li><div class="rounded-box"><b>Research Assistant Roles - Multimodal Corpora using CloudVision</b></div>I worked on
                a multimodal newspaper corpus compilation project with Professor Paul Baker. My role entails writing
                custom Python scripts for collecting the corpus data from several UK newspaper websites, downloading and
                processing the images, interfacing with Google CloudVision and Vertex AI for image tagging, and
                designing the multimodal corpus. Alongside this, this project entails an extensive manual evaluation of using 
                Vertex AI for mutimodal corpus analysis. I have further developed a small tool to display the images based on 
                their tags to enable effective multimodal analyses.</li>
            <li><div class="rounded-box"><b>Technical Assistant Roles - ECR Events</b></div>I did the recording and communication for the
                <a href="https://www.eventbrite.co.uk/e/quantitative-research-methods-for-social-sciences-tickets-308863648487"
                    target="_blank">Quantitative Research Methods for Social Sciences</a> for early career researchers
                event series. The videos of past sessions are available <a
                    href="https://youtube.com/playlist?list=PL_RR3fkE2NtTXZR_MIaIwiH-SBsyLjCWH">here</a>. </li>
            <li><div class="rounded-box"><b>Technical Assistant Roles - BNC launch event</b> </div>I helped with the live stream and
                onsite organisation of the <a
                    href="http://cass.lancs.ac.uk/celebrating-the-written-bnc2014-lancaster-castle-event/">BNC launch
                    event</a> (over 1,200 participants) in 2021. </li>
            <li><div class="rounded-box"><b>Technical Assistant Roles - CHIMED-3 </b></div>I helped with the live stream and onsite
                organisation of the <a href="https://wp.lancs.ac.uk/chimed-3/"> CHIMED-3 </a> conference in 2023. </li>
            <li><div class="rounded-box"><b>Volunteering - Postgraduate Liaison of the LAEL Society</b></div><span class="image right"><img
              src="images/fulls/LAEL.jpg" alt="" /></span>I was the postgraduate
                liaision of the <a href="https://twitter.com/laelsociety">LAEL Society</a> from 02/2020 to 06/2022.
            </li>
            </p>
            <hr class="rounded">
            <h2>Independent Projects and Experience </h2>
            <p>
                <li><div class="rounded-box"><b>COMPILE Learning - Open Access Programming Skills Development</b></div> <span class="image right"><img src="images/fulls/COMPILE.jpg" alt="" /></span>I coordinate the
                    Lancaster branch of <a href="https://www.compilelearning.co.uk" target="_blank">COMPILE</a> and
                    teach select pyhton and regex lectures. <br/><br/><br/><br/><br/></li>
                <li><div class="rounded-box"><b>Lone Wolf Networks</b></div></li>A research project looking at discourses surrounding lone
                    wolf terrorism using network visualisations. </li>
            </p>
            <section id="five">
              <hr class="rounded">
                <h2>Conferences and Presentations</h2>
                <h3>Please click on headings to see abstracts/videos.</h3>
                <h4>CL2021 - 16.-20.07.2021, Limerick Ireland (online)</h4>

                <button class="collapsible">Why Is a Crow Like a Writing Desk? Exploring the Textual and Psychological Reality of Collocation Networks</button>
                <div class="content">
                  <p> </br> I presented findings from my PhD project at the International Conference for Corpus Linguistics.
                  </br> A video of my talk can be accessed here:</br></br> <div class="center-container">  <iframe width="560" height="315"
                    src="https://www.youtube.com/embed/z-WkxbtPrYc?start=976" title="YouTube video player"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe></div> </p>
                </div>

              
                <h4>UCREL - 03.06.2021, Lancaster University (online)</h4>

                <button class="collapsible">Traversing Language Structures: Creating, Exploring and Visualising Large Scale
                  Linguistic Networks</button>
                <div class="content">
                  <p> </br>I gave a talk on "Traversing Language Structures: Creating, Exploring and Visualising Large Scale
                    Linguistic Networks" as part of <a href="https://ucrel.lancs.ac.uk/crs/" target="_blank">the UCREL
                        seminar series</a>. </br> Abstract: How does the language we are surrounded by differ from the
                    language in our Mental Lexicon? We try to explore this question by developing new methods to
                    display, analyse and compare large-scale linguistic networks using graph-theoretical parameters. The
                    aim is to examine structural similarities and differences between a collocation network (based on
                    the BNC2014 / BNC2014 Baby+(Brezina, 2019)) and a psycholinguistic network (based on cue-response
                    pairs provided by over 90,000 participants for the SWOW-EN project (De Deyne et al., 2018)) in order
                    to further our understanding of the relationship between language perception and language
                    production. In addition to this, a new, dynamic visualisation of said networks furthermore allows
                    for identifying "latent patterns" (Dong & Buckingham, 2018) in the data that would not have been
                    observable when starting an analysis using pre-determined words of interest. In this presentation,
                    the methodology and overarching justifications for the project will be presented alongside a
                    demonstration of several custom network visualisations in Cytoscape (Shannon et al., 2003) and a
                    case study exploring properties of the BNC2014 Baby+ and SWOW-EN. </br></br> A video of my talk can be
                    accessed here:</br></br> <div class="center-container">  <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/6FYjih_TIDQ" title="YouTube video player" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe></div> </p>
                </div>

                <h4>'Annotations' Summer School / École thématique d’été « Annotations » - 30.05.-03.06.2022,
                    Banyuls-sur-Mer</h4>

                    <button class="collapsible">Lessons Learnt from Graphing Linguistic Connections</button>
                    <div class="content">
                      <p> </br>I gave a talk titled 'Lessons Learnt from Graphing Linguistic Connections' at the <a
                            href="http://annotations-2022.llf-paris.fr/index.php?langue=en" target="_blank">École thématique
                            d’été « Annotations »</a> in France. This conference/summer school was organised by GDR
                        Lift/Sorbonne. </p>
                    </div>
                  </br>
                <h4>ICAME43 - 27.-30.07.2022, Cambridge, UK</h4>
                <p> <span class="image left"><img src="images/fulls/ICAME43.jpg" alt="" /></span> </br> I presented
                    methodological findings from my PhD project at the 43rd Annual Conference of the International
                    Computer Archive for Modern and Medieval English <a href="https://www.icame43.com"
                        target="_blank">(ICAME) </a> </br> My abstract can be found <a
                        href="https://icame.info/wp-content/uploads/ICAME43_Abstracts_v2.pdf" target="_blank"> here </a>
                    (page 152). </br> </br> </p>
                  
                    <button class="collapsible">Network Visualisations Of Linguistic Relationships In Large Datasets: A Case
                      Study Exploring The Context Of <i>Normal</i> In British English</button>
                    <div class="content">
                      <p> </br>In the wake of many 'new normals' in linguistics, new tools to explore linguistic data are
                        steadily being proposed and implemented. This study aims to showcase one of these
                        novel approaches: large scale linguistic network visualisations and how they can shed
                        light on the interplay between language production and language perception. For the
                        purpose of demonstrating strengths and limitations of this approach we carry out a case
                        study on the basis of the following research questions:
                        What is the collocational embedding of the word normal in spoken British English?
                        What shape might the associative embedding of the word normal in native BrE
                        speaker's mental lexicon take?
                        In order to explore this, a multidisciplinary approach is taken that spans corpus
                        linguistics, psycholinguistics and graph theory. The exact method employed to investigate
                        word embeddings/context here is based on a custom-built python scripts used to pre-
                        process and weight corpus data as well as word association data. First sentence-span
                        tuples from the spoken BNC 2014 (Love et al, 2017) are extracted while retaining their
                        directionality – an often underreported yet crucial property (Michelbacher et al., 2011;
                        Gries; 2013, McConnell & Blumenthal-Dramé, 2019) – and the corresponding MI2 scores
                        are calculated. Then the Small World of Words word association database (SWOW; De
                        Deyne et al, 2019) is processed and filtered to only contain responses by British
                        participants for comparability with the BNC. The obtained collocations (MI2 ≥ 10) and
                        association pairs (Association weight ≥ 1) are fed to Cytoscape (Shannon et al., 2003) via
                        py4cytoscape. The visual representations of the BNC and SWOW-UK networks
                        surrounding the word normal (Figures 1 and 2) are created on the basis of an edge-
                        weighted spring directed layout (Kamada & Kawai, 1989) which roughly maps MI2 scores
                        and association weights onto the displayed distances between words. Lastly, a range of
                        graph theoretical properties for both networks are extracted and interpreted.
                        The results indicate that both the complete SWOW UK network and the complete
                        Spoken BNC 2014 network exhibit small world properties (Watts & Strogatz, 1998).
                        Qualitatively speaking, the collocations surrounding normal in the spoken BNC 2014 are
                        generally sparser and the resulting subnetwork is denser than the one emerging from
                        word associations. In the BNC, key topics surrounding the term are personal relationships
                        and looks. These are organised around a strong network core composed of discourse
                        markers and frequent verbs such as like, really, well etc. The word association dataset,
                        however, looks markedly different and almost fractures into five distinct topic areas:
                        antonyms of normality, society, health, abstract notions of normality, and discourse
                        surrounding drugs. This suggests discrepancies between the mental association
                        processes surrounding abstract terms such as normal and usage of such terms in everyday
                        conversation.
                        Lastly, further applications of this methodology are briefly remarked upon. These
                        include optimising language pedagogy practices (Xiao & McEnery, 2006; Webb &
                        Kagimoto, 2009) via assessing how central certain terms are to a learner's language
                        network and exploring network cliques which is useful for lexicography (Gablasova et al.,
                        2017; Simpson-Vlach & Ellis, 2010) and researching language change (Chen et al., 2018).</p>
                    </div>
                  </br>
                <h4>CL2023 - 03.-06.07.2023, Lancaster, UK</h4>
                <p> <span class="image right"><img src="images/fulls/CL2023.jpg" alt="CL2023 talk" /></span> </br> At
                    CL2023 I presented two papers: <i>Two approaches to collocation networks: GraphColl and LLN </i>
                    (with Vaclav Brezina) and <i>Deconstructing Discourses – A network-based approach to analysing Lone
                        Wolf Terrorism in British Newspapers</i> (see <a
                        href="https://www.lancaster.ac.uk/cl2023/wp-content/blogs.dir/787/files/2023/07/CL-2023-Book-of-Abstracts-02.07.2023.docx"
                        target="_blank">Book of Abstracts</a>).</br>I also helped organise and chair sessions.  </br> </p>

      
                          <button class="collapsible">Two approaches to collocation networks: GraphColl and LLN </i>
                            (with Vaclav Brezina)</button>
                          <div class="content">
                            <p>
                            </br>
                            Abstract (I): This paper compares two
                            approaches to the creation and analysis of collocation networks: the GraphColl function currently
                            available through #LancsBox and #LancsBox X (Brezina et al., 2020) and a Python and Cytoscape-based
                            (Shannon et al., 2003) custom pipeline for visualisation and graph theoretical analysis of
                            corpus-wide linguistic networks (LLN). Collocation networks are used to visualise discourse
                            relationships, "aboutness" of a text or discourse, semantic relations (Pecina, 2010; Xiao & McEnery,
                            2006; Brezina, 2016; Baker, 2016; Brezina et al., 2015) as well as lexicogrammatical features
                            (McEnery & Brezina, 2019). GraphColl is an accessible tool to view collocational relationships
                            localised to a particular area of discourse; it allows selecting a particular set of search terms,
                            association measure parameters, window spans and thresholds, and retains information on the type,
                            lemma and POS level before plotting collocation networks. LLN, on the other hand, is the result of a
                            methodological triangulation (Noble & Heale, 2019; Tucker & Ernestus, 2016) and integration
                            synthesis (Wyatt, 2022) of concepts from corpus linguistics and graph theory. A core difference is
                            that LLN yields graph theoretical parameters that describe all collocations found in the entire
                            corpus thus producing much larger networks. It also incorporates a graph theoretical exploration
                            e.g. in order to compare different corpora via their collocational density, the average distance
                            between their collocates, etc. Beyond these global descriptions, LLN also allows for clustering to
                            explore different 'layers of discourse'. This paper will provide an in-depth demonstration of how
                            the collocation networks generated by the two tools differ. The case study will focus on the topic
                            of substance abuse across discourses represented in the BNC2014 (Brezina et al., 2021; Love et al.,
                            2017). The implications for corpus-based discourse analysis will be discussed. </br> 
                            <div class="center-container">
                              <iframe
                              allow="autoplay; fullscreen" height="282" width="500"
                              src="https://estream.lancaster.ac.uk/Embed.aspx?id=67871&amp;code=dQ~LNA0a5GuIgNJJcjRP46lecKQSkO99c"
                              frameborder="0" allowfullscreen></iframe>
                          </div></br> </p>
                          </div>
                        </br>

                        
                        <button class="collapsible">Deconstructing Discourses – A network-based approach to analysing Lone
                          Wolf Terrorism in British Newspapers</button>
                        <div class="content">
                          <p>
                          </br>
                          Abstract (II). The aim of this paper is to
                    showcase interdisciplinary novel approaches to collocation network analysis via a case study on lone
                    wolf terrorism discourses in the British press using the Lone Wolf Corpus (LWC; Malone, 2020).
                    Aboutness, special functions of words, and semantic relations are highly relevant when examining
                    discursively complex topics such as lone wolf terrorism, and all of these features emerge from
                    collocational profiles (Pecina, 2010; Xiao & McEnery, 2006; Brezina, 2016; Baker, 2016; Brezina et
                    al., 2015). Extending this line of thought, an analysis of clusters containing heavily interrelated
                    collocates can represent different layers of discourses contained in a corpus and thus constitute a
                    valuable addition to the linguist's toolbox. The LWC contains just under 8.5 million words of
                    British newspaper coverage on lone wolf terrorism and serves as the basis for discourse cluster
                    generation. spaCy (Montani et al., 2022) is used for POS-tagging and lemmatising the texts,
                    collocation scores for all sentence-level bigrams (CPN: 6a-LogLikelihood(50), sentence, C0-NC0;
                    filtered to only contain nouns, lexical verbs, adverbs, and adjectives[1]) are then generated in
                    Python. The graph theoretical visualisation and analysis of the remaining list of collocations is
                    carried out via py4cytoscape (Shannon et. al, 2003). Lastly, clusters are extracted using MCODE
                    (Bader & Hogue, 2003) and the Girvan-Newman fast greedy clustering algorithm (Girvan & Newman,
                    2002). Emerging clusters are visualised using edge weighted spring directed layouts (Kamada & Kawai,
                    1989). The results show that topically similar clusters (here: clusters containing temporal and
                    special information related to terrorist attacks, names of terrorists and victims, weapons, and
                    organisations) emerge across the different subsections of the LWC. The observed clusters present a
                    first step towards more holistic insights into discursive patterns while moving away from an
                    exclusively intuition-based starting point for linguistic analysis (Castro & Siew, 2020; Sinclair &
                    Coulthard, 1975; Dong & Buckingham, 2018) .This underlines the notion that the application of graph
                    theoretical methods to language data displays both theoretical and methodological potential
                    (Vitevitch & Goldstein, 2014). [1] Here taken to represent the lexicalised end of the
                    lexicogrammatical spectrum. </br>   
                    
                    <div class="center-container">
                    <iframe allow="autoplay; fullscreen" height="282" width="500"
                    src="https://estream.lancaster.ac.uk/Embed.aspx?id=67913&amp;code=e9~g5OZF3y0OZzlMDlza5Eks5NFkYgpFb"
                    frameborder="0" allowfullscreen></iframe> </div></br> </p>
                        </div>
                      </br>

                <h4>Edge Hill Corpus Research Group - 14.12.2023</h4>
                <p> <span class="image left"><img src="images/fulls/EHRG2023.jpg" alt="Edge Hill talk 2023" /></span>
                    Daniel Malone (Edge Hill) and I presented on 'A pack of lone wolves? Exploring the nexus between the
                    lone-wolf terrorist, Al-Qaeda, and ISIS in the British Press' as part of the Edge Hill Corpus
                    Research Group </i> (see <a href="https://sites.edgehill.ac.uk/crg/past/" target="_blank">EHCRG
                        website</a>)<br> </br> </p>
                        
                        <button class="collapsible">A pack of lone wolves? Exploring the nexus between the
                          lone-wolf terrorist, Al-Qaeda, and ISIS in the British Press</button>
                        <div class="content">
                          <p>
                          Abstract: </br> Following recent events in Belgium and Israel, the
                          lone-wolf terrorist re-emerged in media reportage, with President Joe Biden and former GCHQ Director
                          Sir David Omand expressing concerns over potential attacks in the USA and UK. Days later, Belgian
                          Prime Minister Alexander De Croo described the neutralised Brussels shooter as “probably a lone
                          wolf,” thus aiming to downplay the risk of subsequent incidents. Together, these instances exemplify
                          that by shaping a “reality” (Entman, 2004), (in)security discourses can amplify or downplay a
                          terrorist threat, in turn reflecting and/or influencing public perception and potentially guiding
                          policy responses. Historically, the lone wolf has been associated with different movements, ranging
                          from the propaganda of the deed in the 19th Century to the leaderless resistance of
                          white-supremacist groups in the 1980s and 90s. More recently, it is within the domain of Islamist
                          terrorism, often dominated by Al-Qaeda and ISIS, where the lone wolf has become increasingly
                          associated, especially in the British press. In this joint presentation, we discuss the analytical
                          approaches and results from our analysis of discourses surrounding the lone-wolf terrorist, al
                          Qaeda, and ISIS in three diachronic sub-corpora of the Lone Wolf Corpus (Malone, 2020), a
                          compilation of British Press articles from 2000 to 2019. In a unique methodological combination, we
                          employed large-scale collocation networks and topical clustering to examine shifting discourses
                          through collocational clusters, and applied a corpus-based critical discourse analysis to examine
                          representations of the Al-Qaeda-ISIS nexus. Hanna introduces the methodology employed to generate
                          topical clusters and discusses collocational changes and constants in emerging discourses
                          surrounding the lone-wolf terrorist. The resulting patterns present a discursive shift from clusters
                          related to causative factors (e.g., a mental health subcluster), towards the internationalisation
                          and institutionalisation of lone-wolf terrorism, and finally to response management in the form of
                          sentencing and punitive actions (e.g., a court proceedings/prison subcluster). Reporting on his
                          corpus-based critical discourse analysis, Daniel presents the emergent representations surrounding
                          co-occurrences of the node AL QAEDA with ISIS. These discourses were categorised into four modes of
                          representation of presented relationship-types: Convergence, Association, Dissociation, and
                          Divergence. These modes contributed to surrounding (in)security discourses that at times equate,
                          promote and/or relegate different entities in a continual reshuffling of the threat hierarchy; a
                          process termed here enmity reimagining. </br>  </p>
                        </div>
                      </br>

                <h4>Digital Humanities Forum - 08.02.2024, Lancaster University</h4>
                <p> <span class="image right"><img src="images/fulls/DH2024.jpg"
                            alt="DH Forum Presentation 2024" /></span> I presented parts of my ongoing work on network
                    explorations of linguistic data in my talk titled "Mapping Meaning: Large Linguistic Networks in the
                    Digital Humanities Landscape" with a focus on applicability in the wider DH space. See presentation <a
                      href="https://hannaschmueck.github.io/docs/DHForum2024.pdf">here</a> and visualisations here <a
                      href="https://hannaschmueck.github.io/Networks/spokenBNC2014clusters.html">Spoken BNC</a> & <a
                      href="https://hannaschmueck.github.io/Networks/academicBNC2014clusters.html">Academic BNC</a>.</p>
                <h4>ICAME 45 - 18.06.- 22.06.2024, Vigo, Spain</h4>
                <p> <span class="image left"><img src="images/fulls/ICAME45.jpg"
                            alt="ICAME presentations 2024" /></span> I have had two full papers accepted for ICAME 45 in
                    Vigo. The first paper is a collaboration with Samuel Hollands (Sheffield University) titled
                    <i>Towards a Pipeline Approach to Corpus Compilation: Challenges and Solutions </i> and the second
                    paper is single-authored titled <i> Graphing Registers - Exploring Register Differences via
                        Collocational Networks in the BNC2014 </i> </br></br>

                      </p>
                        
                      <button class="collapsible">Towards a Pipeline Approach to Corpus Compilation: Challenges and Solutions 
                        (with Samuel Hollands)</button>
                      <div class="content">
                        <p>
                          Abstract (I): </br>Despite enormous
                          financial and time investments in many modes of corpus compilation there is often a lack in
                          consistency with regards to corpus processing, format, and structure (Demmen, 2020; Diemer et al.,
                          2016, Reppen, 2022). Issues spanning domains and impacting comparability of spoken and written
                          corpora (Lindquist & Levin, 2000) include irregular metadata formats, inconsistent data structures,
                          varied transcription approaches amongst others. In the domain of speech corpora, we see additional
                          issues such as methodologically unjustified variation in audio formats. This paper aims to explore
                          ways in which both written and spoken corpus compilation can be streamlined and, as an example,
                          which best practices can be employed for constructing eBook corpora. Recommendations relevant to
                          both researchers working with spoken and written corpora are provided in order to highlight the
                          importance of working towards a methodological conversion in these two domains. </br>Within this
                          study we are proposing the Python Corpus Pipeline (PCPi) to streamline corpus compilation via
                          programmatic blueprints for ideal corpus structures. This allows researchers to automatically format
                          corpora into a regular schema and encourages conscious decisions regarding limitations which often
                          occur as a result of the absence of clear guidelines in the corpus creation phase. Specific
                          recommendations are made to address issues in the spoken corpus domain such as varied microphone
                          setups, irreversible acoustic post-processing of recordings, and inconsistent use of audio
                          filetypes. For example, low-bitrate MP3, whilst near universally accepted as a very effective form
                          of signal compression, is designed to remove as much information from an audio signal as possible
                          whilst trying to preserve the human perception of the signal from a psychoacoustic perspective
                          (Watkinson, 2012: 169-227). Therefore, whilst to the human ear the signal may appear unaltered, the
                          information loss caused by signal compression can pose challenges from the perspective of speech
                          scientists such as speech analytics for emotion recognition (Campbell, 2002; Lotz, 2017).</br>In the
                          written domain we provide a worked example from the currently ongoing compilation of the
                          Lancaster-Northern Arizona Corpus of American English (LANA). Even straightforward tasks such as
                          removing the front and backmatter pose significant problems when working with epub files that do not
                          follow a rigorous standard. This is the case since long acknowledgements or reading samples run the
                          risk of mimicking the style of the desired main body of the text and chapter breaks are not reliably
                          marked. The issue of formatting inconsistencies almost always occurs when eBooks are sourced from
                          multiple publishers. As for the fiction section of LANA only 664 out of 1325 books available (50.1%)
                          contained explicit and reliable chapter breaks. This paper describes the subroutine of the PCPi
                          framework. This splits individual files into paragraphs and checks their contents in several passes
                          to classify them as belonging to the main body of the text or not using a window-based approach,
                          resulting in 1133 (85.5%) salvageable eBooks. </br>By advocating for standardized practices and
                          exemplifying its application in eBook corpus construction, this study contributes to the ongoing
                          efforts aimed at fostering methodological coherence within the diverse landscape of corpus
                          linguistics through the oculus of the PCPi framework. </br>  </br>  </p>
                      </div>
                    </br>

                    <button class="collapsible">Graphing Registers - Exploring Register Differences via
                      Collocational Networks in the BNC2014 </button>
                    <div class="content">
                      <p>Abstract (II): </br>One of the many
                      ways in which register differences and linguistic nuances within different fields of discourse can
                      be explored and compared is via collocations, here broadly defined as a commonly co-occurring group
                      or set of words (Barnbrook et al., 2013; Stulpinaitė et al., 2016). Previous research shows that
                      register can be used to partially predict collocations in American English (Berber Sardinha, 2017),
                      and underscores the significance of investigating how linguistic patterns contribute to the
                      distinctive characteristics of various registers. This paper aims to explore register differences in
                      the BNC2014 (v2; Love et al, 2017; Brezina et al., 2021) through the lens of collocational clusters
                      derived from subcorpus-wide collocation networks Acknowledging the often-conflicting definitions of
                      register and genre, this study adopts Biber and Conrad's (2019) interchangeable use of these terms,
                      employing subcorpora of the BNC2014 as proxies for registers. The questions raised in this paper are
                      how well collocation networks can capture register variation, which registers in the BNC2014 are the
                      most collocationally similar/dissimilar, and what unique collocational clusters emerge from each
                      subcorpus. In order to address these, a multidisciplinary approach spanning corpus linguistics and
                      graph theory is used to generate networks of all collocations within each of the 8 subcorpora of the
                      BNC: Academic Language, E-Language, Fiction, Magazines, Newspapers, Written-To-Be-Spoken, Official
                      Documents, and Spoken Language. Following a methodology akin to Karaminis et al. (2023), the
                      collocations are required to lie above both a ΔPforward and logDice threshold to ensure robustness
                      in terms of the forwards predictability and coherence of the collocations. The large linguistic
                      networks (LLNs) generated on the basis of these subcorpora represent the collocational profiles,
                      structure, and aboutness (Pecina, 2010; Xiao & McEnery, 2006; Brezina, 2016; Baker, 2016; Brezina et
                      al., 2015) of the respective registers in the BNC2014. MCODE clustering (Bader & Hogue, 2003) is
                      employed in order to identify the collocationally most closely-interconnected clusters unique to
                      each register.
                            
                        <span class="image left"> <img src="images/fulls/ICAME45_Fig1.png"
                          alt="ICAME presentations 2024"/></span>
                          Employing this methodology serves two purposes: Firstly, it allows for a systematic
                        and fully interpretable exploration of large-scale differences in collocational tendencies among
                        different registers of modern British English, and, secondly, it showcases which new avenues for
                        interpretation a novel approach to collocation visualisation can bring. On a broader scale, notable
                        collocational convergence is observed, with the highest overlap occurring between Magazines and News
                        (20.2%), Spoken and Written-to-be-Spoken (19.9%), and E-Language and Spoken (19.6%). Conversely, the
                        lowest overlap is evident between Official Documents and Written-to-be-Spoken (2.0%), Academic
                        Language and Written-to-be-Spoken (2.3%), and Fiction and Official Documents (3.2%). 
                        <span class="image right"> <img
                          src="images/fulls/ICAME45_Fig2.png" alt="ICAME presentations 2024" /></span> Figures 1 and 2
                        show key clusters from the opposing domains of Official Documents and Written-To-Be-Spoken
                        respectively. This novel multidisciplinary approach integrating corpus linguistics and graph theory
                        with MCODE clustering presents a new way for systematically exploring register variation. </br>
                        <span style="font-size:0.7em">Figure 1: Subcluster containing collocates unique to Official Documents in the BNC2014. </br> Figure 2: Subcluster containing collocates unique to Written-To-Be-Spoken in the BNC2014. </br></span></p>
    
                    </div>
                  </br>


                <h4>ICAME 46 - 17.06.- 21.06.2025, Vilnius, Lithuania</h4>
                <p> I had one full paper and a work in progress report accepted for ICAME 46 in
                    Vilnius. The full paper is based on the evaluation study I did for the <i>Automatic Image Tagging for Corpus Linguistics Cambridge Element</i> with Paul Baker and Yufang Qian. 
                    The Work In Progress Report is based on shared work with Marc Alexander at Glasgow looking at transforming community archives 
                    (and specifically metadata) into coprora. </br></br>

                      </p>
                        
                      <button class="collapsible">A tag is worth a thousand words? Evaluating AI image tagging for multimodal corpus construction</button>
                      <div class="content">
                        <p>
                          Abstract (I): </br>Building on the work on multimodal corpora by McClure et al. (2011), Collins (2020), and especially Baker and Collins (2023), which served as a pilot study for this project, the present study evaluates the usability of an existing AI image tagging tool, Vertex AI (Google Cloud, 2023), for multimodal corpus construction. This avenue of research is exceptionally promising as it enables a broader exploration of the dynamics between words and images, as outlined by Nikolajeva and Scott (2000). Furthermore, it provides a framework for examining how images impact the perceived newsworthiness of events or facts, a concept discussed by Bednarek and Caple (2012) as well as Galtung and Ruge (1965). This paper poses three critical research questions. Firstly, how can we meaningfully evaluate the performance of automatic image tagging tools such as Google Cloud's Vertex AI for corpus linguistic research? Secondly, in the context of a case study on the representation of Muslims in the British press, what level of accuracy does Vertex AI provide in tagging newspaper images? Thirdly, what tools will linguists need to effectively survey multimodal material, such as images, alongside or integrated in traditional corpus tools? The corpus constructed for this project comprises articles from nine UK newspapers collected between December 2022 and December 2023 containing the terms "Muslim" or "Islam," with associated images tagged via Vertex AI. The final corpus contains over 1.5 million tokens from 1,890 articles, 8,546 images, and 89,133 image tags. Images were pushed through the Vertex AI pipeline using a custom Python script, generating up to 50 tags per image alongside corresponding confidence scores. An initial pilot analysis of 100 randomly selected images identified several tagging inaccuracies. High-frequency tags were further scrutinized, with 540 images (15 images per high-frequency tag) evaluated by two independent raters (overall inter-rater agreement 0.79) to assess tag accuracy. Tags such as Building, Chin, Car, Human, and Protest showed high accuracy, while tags like Winter, Gesture, and FashionDesign were less reliable with an overall Precision of 0.54 for the 110 most frequent tags in the dataset. A further finding indicates that some elements of the tagging process, such as the identification of faces, might be partially rule-based and especially error-prone. For instance, the Vertex AI confidence score for constituent elements of a face (e.g., Nose, Chin) was identical across the entire dataset and did not account for cases where parts of a face were obscured. The iterative refinement process, which involved removing unreliable or irrelevant tags, increased overall tag accuracy to approximately 90%. To address research question three, the paper also presents the Image Tag Explorer tool which was developed to view images by tags or adjacent words in the corpus in the hopes of facilitating effective research of multimodal corpora. This paper underscores the transformative potential of multimodal corpus linguistics in understanding complex discourse patterns. The inclusion of image tags provided profound insights into the representation of Islam and Muslims in the context of our case study, enriching traditional text-based analysis. Future directions include integrating custom tags and improving concordance presentation, ensuring the robustness and credibility of multimodal corpus approaches.
                      </br> </p>
                      </div>
                    </br>

                    <button class="collapsible">Exploring the past via archival corpora: The People’s Collection of Wales Corpus (with Marc Alexander)</button>
                    <div class="content">
                      <p>Abstract (II): </br>This work-in-progress paper investigates the potential of utilising archival materials as corpora. Despite the abundance of archival collections across the UK, including institutional and community archives, these resources remain underappreciated and underutilised in corpus linguistic research and the cultural value of language as a heritage object is not sufficiently recognised. The aforementioned collections do, however, offer access to unique and diverse linguistic varieties that are difficult to source elsewhere and often encompass a wide range of subjective and politically charged viewpoints (Fitzgerald, 2022). Inspired by Pagenstecher and Pfänder (2017), this paper emphasises the benefits of stronger cooperation between historians and linguists and proposes a practical approach to strengthening this relationship via creating archival corpora. The approach in this short paper stands out from existing work on transforming historical oral testimonies into spoken corpora (see Clary-Lemon, 2010; Fitzgerald, 2022) in that it focuses on constructing corpora based on secondary textual information such as metadata from large archival collections. We pose two core research questions: What can corpora reveal about communities of practice? How can we transform archival data into corpora? We also offer some initial thoughts on keyness analyses as tools to extract cultural differences in corpora of this type. To explore these questions, we conduct a case study transforming the archival metadata from the People’s Collection Wales (PCW) into a corpus containing over 7.7 million tokens from over 153,000 individual metadata files. This metadata includes a wide range of descriptions of community-generated digital content, such as scans of photographs, transcriptions of letters, interviews, and videos. Our paper details the practical steps of identifying, collecting, and cleaning archival data for corpus research, and illustrates the unique insights that can be uncovered through the use of such archival materials, compared to existing corpora and historical narratives. The study aims to create a resource that provides profound insights into local communities of practice and cultural differences, and highlights language as a formative part of culture. Examining archival corpora like the PCW corpus has immediate applications in sociolinguistics, dialectology, and narrative discourse analysis (Roller, 2015), with further avenues for exploration. Possible research questions relating to this dataset would be e.g. whether – and if so how – the language in community archives systematically differs from language in institutional archives with regards to emotivity. In looking at the past through the lens of archival metadata, this research outlines a future pathway for corpus linguists that aims for a more community-based, culturally aware, and interdisciplinary approach to language.
                        
                            
               </br></p>
    
                    </div>
                  </br>

                <h4>CL2025 - 30.06.- 03.07.2025, Birmingham, UK</h4>

                <p> I will present one full paper with Marc Alexander at CL2025 in Birmingham. </br></br>

                      </p>
                        
                      <button class="collapsible">Hidden in Plaintext: Transforming Archival Metadata into Corpora</button>
                      <div class="content">
                        <p>
                          Abstract (I): </br>

This paper explores the potential of utilising archival materials as corpora, emphasizing the cultural value of language as a heritage object. Despite the wealth of community archives across the UK, these resources remain underappreciated and underutilised in corpus linguistic research. Archives encompass different linguistic varieties and encompass a wide range of subjective and politically charged viewpoints (Fitzgerald, 2022), not to mention having great potential for corpus researchers as their data often contain a range of different genres and modes. Inspired by Pagenstecher and Pfänder (2017), this paper promotes cooperation between archivists and linguists to create archival corpora. Unlike previous work on transforming historical oral testimonies into spoken corpora (see Clary-Lemon, 2010; Fitzgerald, 2022), we focus on constructing corpora from secondary textual information.
Two core research questions guide this study: How can we transform archival data into corpora? What can archival corpora reveal about communities of practice? Our case study involves transforming the archival metadata from the People’s Collection Wales (PCW) into two corpora: one containing over 7.7 million tokens of English descriptions from 153,000 metadata files, and the other containing the Welsh descriptions amounting to 6.8 million tokens from the same number of metadata files. This metadata includes descriptions of community-generated digital content, such as scans of photographs, transcriptions of letters, interviews, and videos, often contributed by volunteers. Our paper details the practical steps of identifying, collecting, and cleaning archival data for corpus research, illustrating the unique insights that can be uncovered through such archival materials compared to existing corpora. We then employ collocation and keyness analyses to explore cultural themes within either corpus and highlight insights into local communities of practice and cultural differences. This research outlines a pathway for corpus linguistics that aims for a more community-based, culturally aware, and interdisciplinary approach to language.
</br> </p>
                      </div>
                    </br>
            </span></p>
                  </br>
                  </section>
                  <hr class="rounded">
            <section id="six">
                <h2>Invited talks/ guest lectures </h2>
                <ul>
                    <li>Corpus Linguistics and Collocation Networks - School of Foreign Languages at the University
                        American College Skopje, North Macedonia</li>
                    <li>Research Management and Open Access via the OSF - COMPILE</li>
                    <li>Lessons learnt from teaching Python - PyData Lancaster, see presentation <a
                            href="https://hannaschmueck.github.io/docs/Compile_PyData.pdf">here</a></li>
                    <li>Mapping Meaning: Large Linguistic Networks in the Digital Humanities Landscape - DH Forum @
                        Lancaster University</li>
                    <li>Large Linguistic Networks: A case study on Lone-Wolf Terrorism in the British Press
                      - University of Glasgow</li>
            </section>
            <section id="seven">
              
                <h2>Attended Conferences and Events (selection) </h2>
                <ul>
                    <li>Brexit means Brexit? Ein Symposium - Akademie der Wissenschaften, Mainz - 03-07 December 2017
                    </li>
                    <li>BAAL Corpus Linguistics Special Interest Group Annual Worskhop: Corpora, Discourse and Society -
                        Lancaster - 13 November 2019 </li>
                    <li>Advanced Language Processing Winter School - ALPS, 17-22 January 2021 </li>
                    <li>Machine Learning for Humanists - N8 CIR June 2021</li>
                    <li>The International Corpus Linguistics Conference 2021 - 13-17 July 2021</li>
                    <li>École thématique d'été « Annotations » - 30 May - 03 June 2022</li>
                    <li>The 43rd Annual Conference of the International Computer Archive for Modern and Medieval English
                        - Corpus Linguistics: A New Normal? 27-30 July 2022 </li>
                    <li>CHIMED-3, 3rd International Conference on Historical Medical Discourse - London - 11-12 May 2023
                    </li>
                    <li>CL2023, 12th International Corpus Linguistics Conference - Lancaster - 03-06 July 2023</li>
                    <li>The 45rd Annual Conference of the International Computer Archive for Modern and Medieval English
                      - Corpus Linguistics: Interlocking Corpora and Register(s): Diversity and Innovation. 28-22 June 2024</li>
                      <li>UCREL NLP Summer School 2024 - 24-26 July 2024</li>
                      <li>Towards a National Collection Conference - 20-21 November 2024</li>
                      <li>BEYOND conference - 25-27 November 2024</li>
                </ul>
                <section id="seven">
                <hr class="rounded">
                <h2>Data visualisation of attended events </h2>
                <iframe src="fun/conferencemap.html" width="100%" height="500" frameborder="0" scrolling="no"></iframe>
              
            
              <hr class="rounded">
                <h2>Interests </h2>
                <p> When I'm not working I really enjoy crafting, painting, playing (video)games (particularly platformers), exploring the Lake District, throwing some darts, and listening to podcasts.
                  I won a <a
                        href=" https://portal.lancaster.ac.uk/portal/news/article/big-bike-conversation-2022-competition-winner">Green
                        Lancaster competition </a>and since also enjoy cycling in and around Lancaster.
                <p>
            </section> <!-- Four -->
            <!--
                <h2>Attended Events</h2>
                
                <p></p>
                
                  <p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
                  This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
                  This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
                  <hr />
                  <header>
                    <h4>Heading with a Subtitle</h4>
                    <p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
                  </header>
                  <p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
                  <header>
                    <h5>Heading with a Subtitle</h5>
                    <p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
                  </header>
                  <p>Language & Cognition - Data Visualisation - Corpus Linguistics - Psycholinguistics - Graph Theory - Collocation Networks. </p>
                  <hr />
                  <h2>Heading Level 2</h2>
                  <h3>Heading Level 3</h3>
                  <h4>Heading Level 4</h4>
                  <h5>Heading Level 5</h5>
                  <h6>Heading Level 6</h6>
                  <hr />
                  <h5>Blockquote</h5>
                  <blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
                  <h5>Preformatted</h5>
                
                </section>
                
                <section id="two">
                <h2>Projects at Lancaster University</h2>
                <div class="row">
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/01.jpg" class="image fit thumb"><img src="images/thumbs/01.jpg" alt="" /></a>
                    <h3>Teaching - Undergraduate Modules</h3>
                    <p>I have been teaching several modules at Lancaster University since 2020.
                    Modules I have taught so far include LING228 (Child Language Acquisition), LING315 (Forensic Linguistics), and LING326 (Corpus Linguistics).</p>
                  </article>
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/02.jpg" class="image fit thumb"><img src="images/thumbs/02.jpg" alt="" /></a>
                    <h3>Ultricies lacinia interdum</h3>
                    <p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
                  </article>
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/03.jpg" class="image fit thumb"><img src="images/thumbs/03.jpg" alt="" /></a>
                    <h3>Teaching - MOOC</h3>
                    <p>I have been deputy lead mentor for Lancaster's "Corpus Linguistics - Method, Analysis, Interpretation" online course. This course runs yearly, has multiple thousands of participants and I have been involved since 2020.</p>
                  </article>
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/04.jpg" class="image fit thumb"><img src="images/thumbs/04.jpg" alt="" /></a>
                    <h3>Teaching and Technical Assistance - Lancaster Summer Schools in Corpus Linguistics</h3>
                    <p>I have been helping with the Lancaster Summer Schools in Corpus Linguistics since 2020. This has involved both teaching Q&A sessions as well as helping with the technology behind the scenes (setting up and recording Teams live events, monitoring the chat).</p>
                  </article>
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/05.jpg" class="image fit thumb"><img src="images/thumbs/05.jpg" alt="" /></a>
                    <h3>Research Assistant Roles - BNC Assistant</h3>
                    <p>I worked on preprocessing and data cleaning of the British National Corpus 2014 from 2020 to its publication in late 2021.</p>
                  </article>
                  <article class="col-6 col-12-xsmall work-item">
                    <a href="images/fulls/06.jpg" class="image fit thumb"><img src="images/thumbs/06.jpg" alt="" /></a>
                    <h3>Research Assistant Roles - Data Processing</h3>
                    <p>I worked on a syntactic coding project doing data cleaning and advanced preprocessing in 2022.</p>
                  </article>
                </div>
                <ul class="actions">
                  <li><a href="#" class="button">Full Portfolio</a></li>
                </ul>
                </section>
                Two -->
            <!--
                <section id="four">
                  <h2>Elements</h2>
                  <section>
                    <h4>Text</h4>
                    <p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
                    This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
                    This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
                    <hr />
                    <header>
                      <h4>Heading with a Subtitle</h4>
                      <p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
                    </header>
                    <p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
                    <header>
                      <h5>Heading with a Subtitle</h5>
                      <p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
                    </header>
                    <p>Language & Cognition - Data Visualisation - Corpus Linguistics - Psycholinguistics - Graph Theory - Collocation Networks. </p>
                    <hr />
                    <h2>Heading Level 2</h2>
                    <h3>Heading Level 3</h3>
                    <h4>Heading Level 4</h4>
                    <h5>Heading Level 5</h5>
                    <h6>Heading Level 6</h6>
                    <hr />
                    <h5>Blockquote</h5>
                    <blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
                    <h5>Preformatted</h5>
                    <pre><code>i = 0;
                while (!deck.isInOrder()) {
                print 'Iteration ' + i;
                deck.shuffle();
                i++;
                }
                print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
                  </section>
                  <section>
                    <h4>Lists</h4>
                    <div class="row">
                      <div class="col-6 col-12-xsmall">
                        <h5>Unordered</h5>
                        <ul>
                          <li>Dolor pulvinar etiam magna etiam.</li>
                          <li>Sagittis adipiscing lorem eleifend.</li>
                          <li>Felis enim feugiat dolore viverra.</li>
                        </ul>
                        <h5>Alternate</h5>
                        <ul class="alt">
                          <li>Dolor pulvinar etiam magna etiam.</li>
                          <li>Sagittis adipiscing lorem eleifend.</li>
                          <li>Felis enim feugiat dolore viverra.</li>
                        </ul>
                      </div>
                      <div class="col-6 col-12-xsmall">
                        <h5>Ordered</h5>
                        <ol>
                          <li>Dolor pulvinar etiam magna etiam.</li>
                          <li>Etiam vel felis at lorem sed viverra.</li>
                          <li>Felis enim feugiat dolore viverra.</li>
                          <li>Dolor pulvinar etiam magna etiam.</li>
                          <li>Etiam vel felis at lorem sed viverra.</li>
                          <li>Felis enim feugiat dolore viverra.</li>
                        </ol>
                        <h5>Icons</h5>
                        <ul class="icons">
                          <li><a href="https://twitter.com/hanna_schmueck" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
                          <li><a href="https://github.com/hannaschmueck" class="icon brands fa-github"><span class="label">Github</span></a></li>
                        </ul>
                      </div>
                    </div>
                    <h5>Actions</h5>
                    <ul class="actions">
                      <li><a href="#" class="button primary">Default</a></li>
                      <li><a href="#" class="button">Default</a></li>
                    </ul>
                    <ul class="actions small">
                      <li><a href="#" class="button primary small">Small</a></li>
                      <li><a href="#" class="button small">Small</a></li>
                    </ul>
                    <div class="row">
                      <div class="col-6 col-12-small">
                        <ul class="actions stacked">
                          <li><a href="#" class="button primary">Default</a></li>
                          <li><a href="#" class="button">Default</a></li>
                        </ul>
                      </div>
                      <div class="col-6 col-12-small">
                        <ul class="actions stacked">
                          <li><a href="#" class="button primary small">Small</a></li>
                          <li><a href="#" class="button small">Small</a></li>
                        </ul>
                      </div>
                      <div class="col-6 col-12-small">
                        <ul class="actions stacked">
                          <li><a href="#" class="button primary fit">Default</a></li>
                          <li><a href="#" class="button fit">Default</a></li>
                        </ul>
                      </div>
                      <div class="col-6 col-12-small">
                        <ul class="actions stacked">
                          <li><a href="#" class="button primary small fit">Small</a></li>
                          <li><a href="#" class="button small fit">Small</a></li>
                        </ul>
                      </div>
                    </div>
                  </section>
                  <section>
                    <h4>Table</h4>
                    <h5>Default</h5>
                    <div class="table-wrapper">
                      <table>
                        <thead>
                          <tr>
                            <th>Name</th>
                            <th>Description</th>
                            <th>Price</th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td>Item One</td>
                            <td>Ante turpis integer aliquet porttitor.</td>
                            <td>29.99</td>
                          </tr>
                          <tr>
                            <td>Item Two</td>
                            <td>Vis ac commodo adipiscing arcu aliquet.</td>
                            <td>19.99</td>
                          </tr>
                          <tr>
                            <td>Item Three</td>
                            <td> Morbi faucibus arcu accumsan lorem.</td>
                            <td>29.99</td>
                          </tr>
                          <tr>
                            <td>Item Four</td>
                            <td>Vitae integer tempus condimentum.</td>
                            <td>19.99</td>
                          </tr>
                          <tr>
                            <td>Item Five</td>
                            <td>Ante turpis integer aliquet porttitor.</td>
                            <td>29.99</td>
                          </tr>
                        </tbody>
                        <tfoot>
                          <tr>
                            <td colspan="2"></td>
                            <td>100.00</td>
                          </tr>
                        </tfoot>
                      </table>
                    </div>
                    <h5>Alternate</h5>
                    <div class="table-wrapper">
                      <table class="alt">
                        <thead>
                          <tr>
                            <th>Name</th>
                            <th>Description</th>
                            <th>Price</th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td>Item One</td>
                            <td>Ante turpis integer aliquet porttitor.</td>
                            <td>29.99</td>
                          </tr>
                          <tr>
                            <td>Item Two</td>
                            <td>Vis ac commodo adipiscing arcu aliquet.</td>
                            <td>19.99</td>
                          </tr>
                          <tr>
                            <td>Item Three</td>
                            <td> Morbi faucibus arcu accumsan lorem.</td>
                            <td>29.99</td>
                          </tr>
                          <tr>
                            <td>Item Four</td>
                            <td>Vitae integer tempus condimentum.</td>
                            <td>19.99</td>
                          </tr>
                          <tr>
                            <td>Item Five</td>
                            <td>Ante turpis integer aliquet porttitor.</td>
                            <td>29.99</td>
                          </tr>
                        </tbody>
                        <tfoot>
                          <tr>
                            <td colspan="2"></td>
                            <td>100.00</td>
                          </tr>
                        </tfoot>
                      </table>
                    </div>
                  </section>
                  <section>
                    <h4>Buttons</h4>
                    <ul class="actions">
                      <li><a href="#" class="button primary">Primary</a></li>
                      <li><a href="#" class="button">Default</a></li>
                    </ul>
                    <ul class="actions">
                      <li><a href="#" class="button large">Large</a></li>
                      <li><a href="#" class="button">Default</a></li>
                      <li><a href="#" class="button small">Small</a></li>
                    </ul>
                    <ul class="actions fit">
                      <li><a href="#" class="button primary fit">Fit</a></li>
                      <li><a href="#" class="button fit">Fit</a></li>
                    </ul>
                    <ul class="actions fit small">
                      <li><a href="#" class="button primary fit small">Fit + Small</a></li>
                      <li><a href="#" class="button fit small">Fit + Small</a></li>
                    </ul>
                    <ul class="actions">
                      <li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
                      <li><a href="#" class="button icon solid fa-download">Icon</a></li>
                    </ul>
                    <ul class="actions">
                      <li><span class="button primary disabled">Primary</span></li>
                      <li><span class="button disabled">Default</span></li>
                    </ul>
                  </section>
                  <section>
                    <h4>Form</h4>
                    <form method="post" action="#">
                      <div class="row gtr-uniform gtr-50">
                        <div class="col-6 col-12-xsmall">
                          <input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
                        </div>
                        <div class="col-6 col-12-xsmall">
                          <input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
                        </div>
                        <div class="col-12">
                          <select name="demo-category" id="demo-category">
                            <option value="">- Category -</option>
                            <option value="1">Manufacturing</option>
                            <option value="1">Shipping</option>
                            <option value="1">Administration</option>
                            <option value="1">Human Resources</option>
                          </select>
                        </div>
                        <div class="col-4 col-12-small">
                          <input type="radio" id="demo-priority-low" name="demo-priority" checked>
                          <label for="demo-priority-low">Low Priority</label>
                        </div>
                        <div class="col-4 col-12-small">
                          <input type="radio" id="demo-priority-normal" name="demo-priority">
                          <label for="demo-priority-normal">Normal Priority</label>
                        </div>
                        <div class="col-4 col-12-small">
                          <input type="radio" id="demo-priority-high" name="demo-priority">
                          <label for="demo-priority-high">High Priority</label>
                        </div>
                        <div class="col-6 col-12-small">
                          <input type="checkbox" id="demo-copy" name="demo-copy">
                          <label for="demo-copy">Email me a copy of this message</label>
                        </div>
                        <div class="col-6 col-12-small">
                          <input type="checkbox" id="demo-human" name="demo-human" checked>
                          <label for="demo-human">I am a human and not a robot</label>
                        </div>
                        <div class="col-12">
                          <textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
                        </div>
                        <div class="col-12">
                          <ul class="actions">
                            <li><input type="submit" value="Send Message" class="primary" /></li>
                            <li><input type="reset" value="Reset" /></li>
                          </ul>
                        </div>
                      </div>
                    </form>
                  </section>
                  <section>
                    <h4>Image</h4>
                    <h5>Fit</h5>
                    <div class="box alt">
                      <div class="row gtr-50 gtr-uniform">
                        <div class="col-12"><span class="image fit"><img src="images/fulls/05.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/04.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/05.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/06.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
                        <div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
                      </div>
                    </div>
                    <h5>Left &amp; Right</h5>
                    <p><span class="image left"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
                    <p><span class="image right"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
                  </section>
                  [LU](https://www.lancaster.ac.uk/linguistics/about/people/hanna-schmueck)
                  [LinkedIn](https://www.linkedin.com/in/hanna-schmück-366a74170/)
                  This website is still being developed - more to follow soon. 
                </section>
                -->
            <!-- Footer -->
            <section id="three">
                <p> I was a Klaus Murmann Doctoral Fellow at Stiftung der deutschen Wirtschaft gGmbH (Foundation of
                    German Business/ UK regional group) and a I am a winner of the Geoffrey Leech Outstanding MA Student Award
                    for my MA in Language and Linguistics.
            </section>
    </div> <!-- Footer -->
    <footer id="footer">
        <div class="inner">
            <ul class="icons">
                <li><a href="https://twitter.com/hanna_schmueck" class="icon brands fa-twitter"><span
                            class="label">Twitter</span></a></li>
                <li><a href="https://github.com/hannaschmueck" class="icon brands fa-github"><span
                            class="label">Github</span></a></li>
                <li><a href="mailto:h.schmueck@lancaster.ac.uk" class="icon solid fa-envelope"><span
                            class="label">Email</span></a></li>
            </ul>
            <ul class="copyright">
                <li>&copy; Hanna Schmück</li>
                <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
            </ul>
        </div>
    </footer> <!-- Scripts -->
    <script src="assets/js/collapse.js"></script>
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.poptrox.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
</body>
